# Multimodal Deep Learning for Emotion Recognition

Dataset Used - [MELD: A Multimodal Multi-Party Dataset for Emotion Recognition in Conversation](https://arxiv.org/pdf/1810.02508.pdf)
<br>
The MELD is an dataset used to emotion classification in conversation. Itcontains about 13,000 utterances from 1,433 dialogues from the TV-series Friends. Each utterance is annotated with emotion and sentiment labels, and encompasses audio, visual, and textual modalities [[1](https://arxiv.org/pdf/1810.02508.pdf)]. 


An example dialog in the MELD dataset [[1](https://arxiv.org/pdf/1810.02508.pdf)]. For this project we have only considered predicted the emotions using 2 modalities - text and speech.
<br>

![image.png](attachment:image.png)
